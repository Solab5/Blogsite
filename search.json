[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello, I‚Äôm Morris Twinomugisha . I‚Äôm a machine learning engineer who loves building data-science and developer tools üë∑üèº‚Äç‚ôÇÔ∏è. I‚Äô‚Äôm as well a stint in management consulting."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nMakerere University, Kampala | UGANDA Bachelors Degree in Statistics | Aug 2019 - July 2022\nSt Mary‚Äôs College Rushoroza | Kabale, UG Uganda Advanced Certificate of Education | Jan 2017 - Nov 2018"
  },
  {
    "objectID": "about.html#trainings",
    "href": "about.html#trainings",
    "title": "About",
    "section": "Trainings",
    "text": "Trainings\nPractical Deep Learning for coders | Fast.ai\nApplied DataScience | WorldQuant University"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nDeep Conclusions | Data Scientist | November 2022 - present\nSolab Associates | Data Analyst - Internship|"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blogsite",
    "section": "",
    "text": "What is it really\n\n\n\n\n\n\n\nposts\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2022\n\n\nMorris Twinomugisha\n\n\n\n\n\n\n  \n\n\n\n\nThe truth about Deep Learning\n\n\n\n\n\n\n\nposts\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2022\n\n\nMorris Twinomugisha\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/blog1/index.html",
    "href": "posts/blog1/index.html",
    "title": "The truth about Deep Learning",
    "section": "",
    "text": "Awesome deep learning\nYeah, I mean it ‚ÄúAwesome!‚Äù. Deep learning is the most awesome, exciting, and interesting stuff I feel every data scientist should brag about. When I started my data science journey, I thought Learning basic machine learning was all until I heard about things like neural networks, NLP, Computer vision, and so forth. I was so eager to learn how deep learning works. Along the journey, I realized every business or institution needs artificial intelligence in all their support systems other than staying in the comfort zone of traditional approaches to problem-solving and innovation.\nHowever, getting started can be hectic and overwhelming since resources are all over the web, and getting the right resources can be difficult unless you have someone already practicing it to guide you, else you can waste a lot of time without getting started.\nYou can imagine what I went through to get started. If you are passionate about deep learning and don‚Äôt know where to start, or maybe you‚Äôve started but feel you aren‚Äôt understanding anything from some random YouTube videos or resources. This short article is meant for you. Allow me to share with you a few of the facts and resources you need to know about deep learning maybe you could consider making a decision you will never regret today. Deep learning has proved to be the best machine learning technique in different areas all over the world including areas like Natural Language Processing (NLP), Computer Vision, Medicine, Biology, Image generation/enhancement, Recommendation systems, Playing games, Robotics, Other applications ‚Äì financial and logistical forecasting; text-to-speech; much more.\nMany experts will say that to get started with deep learning, you need a lot of math, lots of data, lots of expensive computers, or maybe a Ph.D.¬†Trust me anyone irrespective of any field can practice deep learning. As long as you have an internet connection, you can use many online platforms to run deep learning codes on any computer. A commonly used one is a google Collab notebook. For math, simple high school math is sufficient for anyone to get started. The required basic Linear algebra and calculus can be understood along the way.\nIf you‚Äôve done some basic machine learning before, the approach to deep learning is almost the same. This however doesn‚Äôt imply that deep learning is only for those that have done machine learning before, I have seen experts that have progressed with deep learning minus prior machine learning experience. A critique of basic machine learning is that it mainly involves dealing with quantitative data, unlike most deep learning problems.\nDeep learning problems are mostly texts from the web, sound, pictures, and videos among others thus there is always a need to train models that can enable transforming input data into numeric. This is because computers can only understand numbers.\nAll these applications stipulate why every business or institution needs artificial intelligence in all their support systems other than staying in the comfort zone of traditional approaches to problem-solving and innovation. If this has motivated you, you can check on the following resources which I believe can be a very mounting stone for anyone that would like to embark on a new journey of deep learning.\n\nlink to deep learning for coders(by Jeremy Howard and Sylvain Gugger)\nlink to MIT course for deep learning(MIT)\nLink to Coursera deep learning course(by Andrew Ng)"
  },
  {
    "objectID": "posts/blog2/index.html#what-is-it-really",
    "href": "posts/blog2/index.html#what-is-it-really",
    "title": "What is it really",
    "section": "WHAT IS IT REALLY?",
    "text": "WHAT IS IT REALLY?\nIn 2015 the idea of creating a computer system that could recognise images was considered so outrageously challenging that it was the basis of this XKCD joke:\n\nIn this tutorial we are going to create a computer vision model that can classify whether an image is a car, plane, train or bicycle.\nBy the end of this tutorial, you will be able to implemenent an image classification model in just a few minutes, using entirely free resources!. We shall be using the fastai library A high framework library built on top of pytorch. Feel free to see the ducumentation here for more understanding.\nThe basic steps we‚Äôll take are:\n\nUse DuckDuckGo to search for images of car, plane, train or bicycle photos.\nFine-tune a pretrained neural network to recognise the groups\nTry running this model on a picture of a plane and see if it works."
  },
  {
    "objectID": "posts/blog2/index.html#step-1-download-images-of-plane-train-car-and-bicycles.",
    "href": "posts/blog2/index.html#step-1-download-images-of-plane-train-car-and-bicycles.",
    "title": "What is it really",
    "section": "Step 1: Download images of plane, train, car and bicycles.",
    "text": "Step 1: Download images of plane, train, car and bicycles.\nThe first thing we are going to do is to install the latest versions of fastai and duckduckgo_search since we shall be using it to search images on the internet.\n\n!pip install -Uqq fastai duckduckgo_search\n\nWe create a search_images function that we shall use to iterate on the different terms we shall be searching on the web.\n\nfrom duckduckgo_search import ddg_images\nfrom fastcore.all import *\n\ndef search_images(term, max_images=100):\n    print(f\"Searching for '{term}'\")\n    return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\nLet‚Äôs start by searching for a plane photo and see what kind of result we get. We‚Äôll start by getting URLs from a search:\n\n#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n#    If you get a JSON error, just try running it again (it may take a couple of tries).\nurls = search_images('plane photos', max_images=1)\nurls[0]\n\nSearching for 'plane photos'\n\n\n'http://airplanes.itsabouttravelling.com/wp-content/uploads/2020/02/c-fjzs-air-canada-boeing-777-300er-02-scaled.jpg'\n\n\n‚Ä¶and then download a URL and take a look at it:\n\nfrom fastdownload import download_url\ndest = 'plane.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nfrom fastai.vision.all import *\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\nNow let‚Äôs do the same with ‚Äúcar photos‚Äù and see if it works as well:\n\ndownload_url(search_images('car photos', max_images=1)[0], 'car.jpg', show_progress=False)\nImage.open('car.jpg').to_thumb(256,256)\n\nSearching for 'car photos'\n\n\n\n\n\nOur searches seem to be giving reasonable results, so let‚Äôs grab a few examples of each of ‚Äúplane‚Äù, ‚Äúcar‚Äù, ‚Äútrain‚Äù and ‚Äúbicycle‚Äù photos, and save each group of photos to a different folder:\n\nvehicles = 'car','train', 'bicycle', 'plane'\npath = Path('vehicles')\n\nfor o in vehicles:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'car photo'\nSearching for 'train photo'\nSearching for 'bicycle photo'\nSearching for 'plane photo'"
  },
  {
    "objectID": "posts/blog2/index.html#step-2-train-our-model",
    "href": "posts/blog2/index.html#step-2-train-our-model",
    "title": "What is it really",
    "section": "Step 2: Train our model",
    "text": "Step 2: Train our model\nSome photos might not download correctly which could cause our model training to fail, so we‚Äôll remove them:\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n17\n\n\nTo train a model, we‚Äôll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model ‚Äì not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:\n\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock),\nThe inputs to our model are images, and the outputs are categories (in this case, ‚Äúplane‚Äù, ‚Äúcar‚Äù, ‚Äútrain‚Äù or ‚Äúbicycle‚Äù).\nget_items=get_image_files, \nTo find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42),\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label,\nThe labels (y values) is the name of the parent of each file (i.e.¬†the name of the folder they‚Äôre in, which will be pane, car, train, or bicycle).\nitem_tfms=[Resize(192, method='squish')]\nBefore training, resize each image to 192x192 pixels by ‚Äúsquishing‚Äù it (as opposed to cropping it).\nNow we‚Äôre ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 20 seconds‚Ä¶)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we‚Äôll use that.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.820234\n      0.014370\n      0.000000\n      00:09\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.037691\n      0.001882\n      0.000000\n      00:05\n    \n    \n      1\n      0.032922\n      0.003439\n      0.000000\n      00:04\n    \n    \n      2\n      0.022986\n      0.003907\n      0.000000\n      00:04\n    \n  \n\n\n\nGenerally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n‚ÄúFine-tuning‚Äù a model means that we‚Äôre starting with a model someone else has trained using some other dataset (called the pretrained model), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in imagenet, and widely-used computer vision dataset with images covering 1000 categories).\nAnd another interesting thing to look at when dealing with categorical independent variables is that you can run a confusion matrix which gives you a visual representation and a sense on what classes are hard to predict. For our case, there is no time any class is being predicted wrongly which means that our model is performing very well.\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()"
  },
  {
    "objectID": "posts/blog2/index.html#step-3-use-our-model",
    "href": "posts/blog2/index.html#step-3-use-our-model",
    "title": "What is it really",
    "section": "Step 3: Use our model",
    "text": "Step 3: Use our model\nLet‚Äôs see what our model thinks about that car we downloaded at the start:\n\npred,_,probs = learn.predict(PILImage.create('car.jpg'))\n\n\n\n\n\n\n\n\n\nprint(f\"This is a: {pred}.\")\nprint(f\"Probability it's a car: {probs[1]:.4f}\")\n\nThis is a: car.\nProbability it's a car: 1.0000\n\n\nWe can then pass export to our learner to save our model as a pickel file. This means that any one now can use our model for making predictions\n\nlearn.export('model.pkl')\n\nGood job, resnet18. :)\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from ‚Äúso hard it‚Äôs a joke‚Äù to ‚Äútrivially easy and free‚Äù!\nIt‚Äôs not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including creating amazing artworks, and explaining jokes. It‚Äôs moving so fast that even experts in the field have trouble predicting how it‚Äôs going to impact society in the coming years.\nOne thing is clear ‚Äì it‚Äôs important that we all do our best to understand this technology, because otherwise we‚Äôll get left behind!"
  },
  {
    "objectID": "Publication.html",
    "href": "Publication.html",
    "title": "Blogsite",
    "section": "",
    "text": "Unsupervised Machine Learning For Early Faulty Device Detection\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/first/index.html",
    "href": "publications/first/index.html",
    "title": "Unsupervised Machine Learning For Early Faulty Device Detection",
    "section": "",
    "text": "Early faulty detection in air quality sensors is of increasing importance in ensuring reliable and accurate air quality readings. These sensors play a critical role in monitoring the pollution levels in the atmosphere however, due to their exposure to harsh weather, it‚Äôs natural that they will face wear and may require periodical servicing. The devices are rarely monitored in most cases, particularly in Uganda. The objective of this research is to build a model for the early detection of faulty sensors for replacement and repair. Using the unsupervised learning approaches in particular K-means and PCA; we train a predictive model and later evaluate it for accuracy using a test dataset. From the cluster analysis, the research identified 3 clusters that are; the health state cluster, nearing fault state cluster, and the faulty state cluster. The research discovered that there is no significant difference in adopting PCA as a preprocessing step in using the K-means algorithm. The research further recommended other clustering methods to be used to compare the accuracy score. It also recommended using more attributes for PCA to be effective.\nDownload paper on Makerere University Dissertation repository here or research gate here"
  }
]